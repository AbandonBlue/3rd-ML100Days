{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Day097_Keras_CNN_vs_DNN.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7eFk30oB2vP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "c9c9a160-6e81-4a89-a71a-b1f7ab1b8a41"
      },
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import RMSprop, Adam\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddXxRtU1B2vg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "2f85b755-cb40-4edf-8d46-20d2891b6359"
      },
      "source": [
        "batch_size = 128  # batch 的大小，如果出現 OOM error，請降低這個值\n",
        "num_classes = 10  # 多分類, 類別的數量, Cifar 10 共有 10 個類別\n",
        "epochs = 10       # 訓練的 epochs數量\n",
        "\n",
        "# 讀取資料並檢視\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# 對 label 進行 one-hot encoding (y_trian 原本是純數字)\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 13s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWA9tUsmB2vq",
        "colab_type": "text"
      },
      "source": [
        "## 首先我們使用一般的 DNN (MLP) 來訓練\n",
        "- 由於 DNN 只能輸入一維的資料，我們要先將影像進行攤平，若 (50000, 32, 32, 3) 的影像，攤平後會變成 (50000, 32 * 32 * 3) = (50000, 3072)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tE47XOFWB2vs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "75ab3059-6ab2-4991-d30d-669551869ced"
      },
      "source": [
        "# 將資料攤平成一維資料\n",
        "x_train = x_train.reshape(50000, 3072) \n",
        "x_test = x_test.reshape(10000, 3072)\n",
        "\n",
        "# 將資料變為 float32 並標準化\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6_PGl5xB2vw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5969d902-efeb-45da-e127-67843ec640ee"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(3072,)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,             # 會顯示進度條, 有0-->不顯示, 1, 2--->為每個epoch輸出\n",
        "                    validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 512)               1573376   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,841,162\n",
            "Trainable params: 1,841,162\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "50000/50000 [==============================] - 12s 233us/step - loss: 2.1727 - acc: 0.2506 - val_loss: 1.8477 - val_acc: 0.3334\n",
            "Epoch 2/10\n",
            "50000/50000 [==============================] - 2s 39us/step - loss: 1.8611 - acc: 0.3263 - val_loss: 1.7592 - val_acc: 0.3614\n",
            "Epoch 3/10\n",
            "50000/50000 [==============================] - 2s 38us/step - loss: 1.7777 - acc: 0.3616 - val_loss: 1.7132 - val_acc: 0.3821\n",
            "Epoch 4/10\n",
            "50000/50000 [==============================] - 2s 40us/step - loss: 1.7215 - acc: 0.3821 - val_loss: 1.7310 - val_acc: 0.3676\n",
            "Epoch 5/10\n",
            "50000/50000 [==============================] - 2s 38us/step - loss: 1.6904 - acc: 0.3935 - val_loss: 1.6386 - val_acc: 0.4266\n",
            "Epoch 6/10\n",
            "50000/50000 [==============================] - 2s 40us/step - loss: 1.6569 - acc: 0.4082 - val_loss: 1.6158 - val_acc: 0.4122\n",
            "Epoch 7/10\n",
            "50000/50000 [==============================] - 2s 39us/step - loss: 1.6351 - acc: 0.4124 - val_loss: 1.5683 - val_acc: 0.4423\n",
            "Epoch 8/10\n",
            "50000/50000 [==============================] - 2s 40us/step - loss: 1.6161 - acc: 0.4198 - val_loss: 1.5713 - val_acc: 0.4480\n",
            "Epoch 9/10\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.6034 - acc: 0.4249 - val_loss: 1.5503 - val_acc: 0.4472\n",
            "Epoch 10/10\n",
            "50000/50000 [==============================] - 2s 40us/step - loss: 1.5867 - acc: 0.4309 - val_loss: 1.5193 - val_acc: 0.4647\n",
            "Test loss: 1.5192634298324585\n",
            "Test accuracy: 0.4647\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiVsFlW5B2v1",
        "colab_type": "text"
      },
      "source": [
        "## 接下來我們使用 CNN 來訓練神經網路\n",
        "CNN 的原理非常適合處理影像類的資料，就讓我們來看看，同樣的訓練條件，CNN 是否顯著優於 DNN 呢?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZ476VFVB2v3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "8d35d98e-53d8-4be6-beb4-1bb02a888319"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFAczqxBB2v8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4da301b8-1197-4768-eaa3-f37a335f7f19"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))   # (50000, 32, 32, 3)\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,250,858\n",
            "Trainable params: 1,250,858\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 1.7454 - acc: 0.3698 - val_loss: 1.4389 - val_acc: 0.4839\n",
            "Epoch 2/10\n",
            "50000/50000 [==============================] - 6s 111us/step - loss: 1.2952 - acc: 0.5389 - val_loss: 1.0917 - val_acc: 0.6150\n",
            "Epoch 3/10\n",
            "50000/50000 [==============================] - 6s 111us/step - loss: 1.0882 - acc: 0.6174 - val_loss: 0.9955 - val_acc: 0.6606\n",
            "Epoch 4/10\n",
            "50000/50000 [==============================] - 6s 112us/step - loss: 0.9566 - acc: 0.6650 - val_loss: 0.8581 - val_acc: 0.7022\n",
            "Epoch 5/10\n",
            "50000/50000 [==============================] - 6s 110us/step - loss: 0.8684 - acc: 0.6978 - val_loss: 0.8492 - val_acc: 0.6992\n",
            "Epoch 6/10\n",
            "50000/50000 [==============================] - 6s 110us/step - loss: 0.7970 - acc: 0.7236 - val_loss: 0.7543 - val_acc: 0.7430\n",
            "Epoch 7/10\n",
            "50000/50000 [==============================] - 6s 111us/step - loss: 0.7448 - acc: 0.7421 - val_loss: 0.7684 - val_acc: 0.7419\n",
            "Epoch 8/10\n",
            "50000/50000 [==============================] - 6s 110us/step - loss: 0.7048 - acc: 0.7568 - val_loss: 0.6714 - val_acc: 0.7689\n",
            "Epoch 9/10\n",
            "50000/50000 [==============================] - 6s 111us/step - loss: 0.6719 - acc: 0.7675 - val_loss: 0.6905 - val_acc: 0.7654\n",
            "Epoch 10/10\n",
            "50000/50000 [==============================] - 5s 110us/step - loss: 0.6450 - acc: 0.7784 - val_loss: 0.6671 - val_acc: 0.7742\n",
            "Test loss: 0.6671488645553589\n",
            "Test accuracy: 0.7742\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4NIo35wB2wJ",
        "colab_type": "text"
      },
      "source": [
        "## 同樣運算 10 個 epochs，但 CNN 在 test data 的準確率顯著優於 DNN!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StNyfs64B2wK",
        "colab_type": "text"
      },
      "source": [
        "## 作業\n",
        "1. 請試著調整各個超參數，並說明那些超參數對於結果有明顯的影響?\n",
        "2. CNN 與 DNN 哪個模型的參數數量比較多? 造成參數的數量不同的原因在哪?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-ejOowlD82F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4b9860a7-e861-4551-fed3-b0bbdffe4ee8"
      },
      "source": [
        "# 用一個dropout不要那麼多的\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))   # (50000, 32, 32, 3)\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))                 # this part\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_5 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 13, 13, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,250,858\n",
            "Trainable params: 1,250,858\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "50000/50000 [==============================] - 6s 120us/step - loss: 1.7386 - acc: 0.3768 - val_loss: 1.7535 - val_acc: 0.4025\n",
            "Epoch 2/10\n",
            "50000/50000 [==============================] - 6s 110us/step - loss: 1.2858 - acc: 0.5422 - val_loss: 1.1549 - val_acc: 0.5900\n",
            "Epoch 3/10\n",
            "50000/50000 [==============================] - 6s 110us/step - loss: 1.0652 - acc: 0.6252 - val_loss: 0.9409 - val_acc: 0.6670\n",
            "Epoch 4/10\n",
            "50000/50000 [==============================] - 6s 111us/step - loss: 0.9214 - acc: 0.6787 - val_loss: 0.8810 - val_acc: 0.6963\n",
            "Epoch 5/10\n",
            "50000/50000 [==============================] - 6s 110us/step - loss: 0.8158 - acc: 0.7162 - val_loss: 0.8211 - val_acc: 0.7133\n",
            "Epoch 6/10\n",
            "50000/50000 [==============================] - 5s 109us/step - loss: 0.7339 - acc: 0.7450 - val_loss: 0.7197 - val_acc: 0.7504\n",
            "Epoch 7/10\n",
            "50000/50000 [==============================] - 6s 111us/step - loss: 0.6671 - acc: 0.7690 - val_loss: 0.7588 - val_acc: 0.7428\n",
            "Epoch 8/10\n",
            "50000/50000 [==============================] - 5s 110us/step - loss: 0.6096 - acc: 0.7888 - val_loss: 0.6762 - val_acc: 0.7721\n",
            "Epoch 9/10\n",
            "50000/50000 [==============================] - 6s 111us/step - loss: 0.5660 - acc: 0.8040 - val_loss: 0.6574 - val_acc: 0.7769\n",
            "Epoch 10/10\n",
            "50000/50000 [==============================] - 6s 111us/step - loss: 0.5274 - acc: 0.8173 - val_loss: 0.6996 - val_acc: 0.7725\n",
            "Test loss: 0.6996168983459473\n",
            "Test accuracy: 0.7725\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3F-OScTfEZ26",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fffac072-163d-47bc-bfc1-e9eccb5e5138"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))   # (50000, 32, 32, 3)\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))                      # 多加一層\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_9 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 28, 28, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_15 (Activation)   (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_16 (Activation)   (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 12, 12, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_17 (Activation)   (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "activation_18 (Activation)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_19 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,260,106\n",
            "Trainable params: 1,260,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "50000/50000 [==============================] - 7s 145us/step - loss: 1.8183 - acc: 0.3422 - val_loss: 1.7323 - val_acc: 0.3955\n",
            "Epoch 2/10\n",
            "50000/50000 [==============================] - 6s 126us/step - loss: 1.3778 - acc: 0.5089 - val_loss: 1.2294 - val_acc: 0.5530\n",
            "Epoch 3/10\n",
            "50000/50000 [==============================] - 6s 126us/step - loss: 1.1703 - acc: 0.5881 - val_loss: 1.0319 - val_acc: 0.6326\n",
            "Epoch 4/10\n",
            "50000/50000 [==============================] - 6s 126us/step - loss: 1.0234 - acc: 0.6430 - val_loss: 0.9928 - val_acc: 0.6600\n",
            "Epoch 5/10\n",
            "50000/50000 [==============================] - 6s 128us/step - loss: 0.9167 - acc: 0.6793 - val_loss: 0.8267 - val_acc: 0.7101\n",
            "Epoch 6/10\n",
            "50000/50000 [==============================] - 6s 126us/step - loss: 0.8378 - acc: 0.7081 - val_loss: 0.8279 - val_acc: 0.7137\n",
            "Epoch 7/10\n",
            "50000/50000 [==============================] - 6s 127us/step - loss: 0.7815 - acc: 0.7261 - val_loss: 0.7501 - val_acc: 0.7410\n",
            "Epoch 8/10\n",
            "50000/50000 [==============================] - 6s 127us/step - loss: 0.7406 - acc: 0.7438 - val_loss: 0.7343 - val_acc: 0.7485\n",
            "Epoch 9/10\n",
            "50000/50000 [==============================] - 6s 127us/step - loss: 0.7029 - acc: 0.7559 - val_loss: 0.7804 - val_acc: 0.7351\n",
            "Epoch 10/10\n",
            "50000/50000 [==============================] - 6s 127us/step - loss: 0.6790 - acc: 0.7635 - val_loss: 0.7801 - val_acc: 0.7452\n",
            "Test loss: 0.7801330856800079\n",
            "Test accuracy: 0.7452\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppxj44edE_6R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fc40ab66-e8f9-48dc-9a4f-48dcf32d44b9"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))   # (50000, 32, 32, 3)\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "# model.add(Conv2D(32, (3, 3)))                      # 多加一層\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=20,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_14 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_20 (Activation)   (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_21 (Activation)   (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "activation_22 (Activation)   (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_23 (Activation)   (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 13, 13, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_24 (Activation)   (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "activation_25 (Activation)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_26 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,250,858\n",
            "Trainable params: 1,250,858\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "50000/50000 [==============================] - 6s 126us/step - loss: 1.7265 - acc: 0.3741 - val_loss: 1.5388 - val_acc: 0.4576\n",
            "Epoch 2/20\n",
            "50000/50000 [==============================] - 6s 111us/step - loss: 1.3024 - acc: 0.5370 - val_loss: 1.1767 - val_acc: 0.5770\n",
            "Epoch 3/20\n",
            "50000/50000 [==============================] - 6s 113us/step - loss: 1.1114 - acc: 0.6099 - val_loss: 1.0207 - val_acc: 0.6424\n",
            "Epoch 4/20\n",
            "50000/50000 [==============================] - 6s 112us/step - loss: 0.9862 - acc: 0.6548 - val_loss: 0.9221 - val_acc: 0.6815\n",
            "Epoch 5/20\n",
            "50000/50000 [==============================] - 6s 114us/step - loss: 0.8930 - acc: 0.6886 - val_loss: 0.8325 - val_acc: 0.7115\n",
            "Epoch 6/20\n",
            "50000/50000 [==============================] - 6s 116us/step - loss: 0.8251 - acc: 0.7123 - val_loss: 0.7861 - val_acc: 0.7250\n",
            "Epoch 7/20\n",
            "50000/50000 [==============================] - 6s 113us/step - loss: 0.7729 - acc: 0.7303 - val_loss: 0.8318 - val_acc: 0.7244\n",
            "Epoch 8/20\n",
            "50000/50000 [==============================] - 6s 114us/step - loss: 0.7300 - acc: 0.7450 - val_loss: 0.7139 - val_acc: 0.7575\n",
            "Epoch 9/20\n",
            "50000/50000 [==============================] - 6s 113us/step - loss: 0.6976 - acc: 0.7568 - val_loss: 0.7397 - val_acc: 0.7537\n",
            "Epoch 10/20\n",
            "50000/50000 [==============================] - 6s 112us/step - loss: 0.6662 - acc: 0.7676 - val_loss: 0.8020 - val_acc: 0.7515\n",
            "Epoch 11/20\n",
            "50000/50000 [==============================] - 6s 114us/step - loss: 0.6503 - acc: 0.7763 - val_loss: 0.6969 - val_acc: 0.7632\n",
            "Epoch 12/20\n",
            "50000/50000 [==============================] - 6s 112us/step - loss: 0.6404 - acc: 0.7786 - val_loss: 0.6822 - val_acc: 0.7736\n",
            "Epoch 13/20\n",
            "50000/50000 [==============================] - 6s 114us/step - loss: 0.6214 - acc: 0.7872 - val_loss: 0.6842 - val_acc: 0.7792\n",
            "Epoch 14/20\n",
            "50000/50000 [==============================] - 6s 113us/step - loss: 0.6196 - acc: 0.7887 - val_loss: 0.8179 - val_acc: 0.7398\n",
            "Epoch 15/20\n",
            "50000/50000 [==============================] - 6s 113us/step - loss: 0.6141 - acc: 0.7940 - val_loss: 0.7018 - val_acc: 0.7663\n",
            "Epoch 16/20\n",
            "50000/50000 [==============================] - 6s 114us/step - loss: 0.6093 - acc: 0.7936 - val_loss: 0.7666 - val_acc: 0.7708\n",
            "Epoch 17/20\n",
            "50000/50000 [==============================] - 6s 113us/step - loss: 0.6100 - acc: 0.7963 - val_loss: 0.7107 - val_acc: 0.7701\n",
            "Epoch 18/20\n",
            "50000/50000 [==============================] - 6s 113us/step - loss: 0.6058 - acc: 0.7961 - val_loss: 0.7020 - val_acc: 0.7668\n",
            "Epoch 19/20\n",
            "50000/50000 [==============================] - 6s 113us/step - loss: 0.5984 - acc: 0.7990 - val_loss: 0.7834 - val_acc: 0.7673\n",
            "Epoch 20/20\n",
            "50000/50000 [==============================] - 6s 112us/step - loss: 0.6064 - acc: 0.7951 - val_loss: 0.7087 - val_acc: 0.7746\n",
            "Test loss: 0.7086609377861023\n",
            "Test accuracy: 0.7746\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y92xGYyiDBe5",
        "colab_type": "text"
      },
      "source": [
        "## Answer\n",
        "1. 變動dropout沒有明顯改變, 多加一層卷積層反而下降了...還是是說要調整epoch??\n",
        "  epoch調整多--->改變也不大\n",
        "2. 這題就非常奇怪....你CNN、DNN的model有什麼基準去做比較嗎?不然比參數有何意義?\n",
        "  層數結構都不相同...不過是CNN比較小, Dense與卷積算法不一樣, 且CNN有做pooling,\n",
        "  會減少參數量。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_gVAlISB2wL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}